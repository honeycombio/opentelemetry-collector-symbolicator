# OpenTelemetry Collector Symbolicator Processor

An OpenTelemetry collector processor that will symbolicate JavaScript stack traces using source maps. This is compatible with [v0.12.0](https://github.com/honeycombio/honeycomb-opentelemetry-web/releases/tag/honeycomb-opentelemetry-web-v0.12.0) and onwards of the Honeycomb OpenTelemetry web SDK.

To install this processor, include it in the build config file of your OpenTelemetry collector distro. You can also use the pre-built [Honeycomb OpenTelemetry collector distro](https://github.com/honeycombio/honeycomb-collector-distro) that already includes this processor.

## Requirements

- We require the use of CGO for the processors. If you are building your own collector image it must support glibc. We recommend `gcr.io/distroless/cc`

## JavaScript Source Maps

‚ÑπÔ∏è Prior to release [`sourcemapprocessor/v0.0.10`](https://github.com/honeycombio/opentelemetry-collector-symbolicator/releases/tag/sourcemapprocessor%2Fv0.0.10) this was called `symbolicatorprocessor`.

‚ÑπÔ∏è Logs are not officially supported yet.

### Basic Configuration

Register the plugin in the processors section of your open telemetry collector configuration.

```yaml
    processors:
      source_map_symbolicator:
```

### JavaScript source and source map files

The symbolicator requires access to both your minimised JavaScript source files
and associated JavaScript source map files generated by your build process.
Ideally these files are versioned with a file hash in the file name.
eg. `main.c383b093b0b66825a9c3.js`. The minimised source file must also contain
the `sourceMappingURL` tag containing the relative path to the source map file.
The symbolicator can access these files through a number of [different storage
mechanisms documented below](#storage-mechanisms).

### Exception information format

The processor expects the stacktrace information to be formatted into four separate attributes:

- columns
- functions
- lines
- urls

Each of these attributes must be a slice with each being of equal length.

Example:

```json
columns: [6465,3512358,3512661,3514018,758545]
functions: ["?","w.callback","push.Br+g.w.crossDomainError","XMLHttpRequest.<anonymous>","XMLHttpRequest.<anonymous>"]
lines: [3582,2,2,2,2]
urls: ["https://example.com/static/dist/main.c383b093b0b66825a9c3.js","https://example.com/static/dist/vendor.1c285a50f5307be9648d.js","https://example.com/static/dist/vendor.1c285a50f5307be9648d.js","https://example.com/static/dist/vendor.1c285a50f5307be9648d.js","https://example.com/static/dist/vendor.1c285a50f5307be9648d.js"]
```

### Advanced Configuration

#### Attribute Mapping

The following configuration options can also be provided to change the attributes used to look for stack traces and store them.

| Config Key                                   | Description                                                                                       | Example Value                                        |
| -------------------------------------------- | ------------------------------------------------------------------------------------------------- | ---------------------------------------------------- |
| `symbolicator_failure_attribute_key`         | Signals if the the symbolicator fails to fully symbolicate the stack trace                        | `exception.symbolicator.failed`                      |
| `symbolicator_error_attribute_key`           | Contains the error message if the the symbolicator fails to fully symbolicate the stack trace     | `exception.symbolicator.error`                       |
| `symbolicator_parsing_method_attribute_key` | Stores the stack trace parsing method used by the processor                                       | `exception.symbolicator.parsing_method`            |
| `columns_attribute_key`                      | Which attribute should the columns of the stack trace be sourced from                             | `exception.structured_stacktrace.columns`            |
| `functions_attribute_key`                    | Which attribute should the functions of the stack trace be sourced from                           | `exception.structured_stacktrace.functions`          |
| `lines_attribute_key`                        | Which attribute should the lines of the stack trace be sourced from                               | `exception.structured_stacktrace.lines`              |
| `urls_attribute_key`                         | Which attribute should the urls of the stack trace be sourced from                                | `exception.structured_stacktrace.urls`               |
| `stack_trace_attribute_key`                  | Which attribute should the symbolicated stack trace be populated into                             | `exception.stacktrace`                               |
| `exception_type_attribute_key`               | Which attribute contains the exception type                                                       | `exception.type`                                     |
| `exception_message_attribute_key`            | Which attribute contains the exception message                                                    | `exception.message`                                  |
| `preserve_stack_trace`                       | After the stack trace has been symbolicated should the original values be preserved as attributes | `true`                                               |
| `original_stack_trace_attribute_key`         | If the stack trace is being preserved which key should it be copied to                            | `exception.stacktrace.original`                      |
| `original_columns_attribute_key`             | If the stack trace is being preserved which key should the functions be copied to                 | `exception.structured_stacktrace.functions.original` |
| `original_functions_attribute_key`           | If the stack trace is being preserved which key should the lines be copied to                     | `exception.structured_stacktrace.lines.original`     |
| `original_lines_attribute_key`               | If the stack trace is being preserved which key should the columns be copied to                   | `exception.structured_stacktrace.columns.original`   |
| `original_urls_attribute_key`                | If the stack trace is being preserved which key should the urls be copied to                      | `exception.structured_stacktrace.urls.original`      |

#### Additional Options

| Config Key              | Description                                                                                                       | Example Value |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------- | ------------- |
| `timeout`               | Max duration to wait to symbolicate a stack trace in seconds.                                                     | `5`           |
| `source_map_cache_size` | The maximum number of source maps to cache. Reduce this if you are running into memory issues with the collector. | `128`         |

#### Language-Based Routing

The source map processor supports language-based routing to ensure it only processes signals from JavaScript/TypeScript applications. This prevents the processor from running on signals from other languages (like Java or Swift), improving performance and avoiding unnecessary processing.

| Config Key               | Description                                                                                                                                                    | Default Value             | Example Values                   |
| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------- | -------------------------------- |
| `language_attribute_key` | The attribute key that contains the programming language or SDK language of the telemetry signal.                                                              | `telemetry.sdk.language`  | `telemetry.sdk.language`         |
| `allowed_languages`      | A list of language values that this processor will handle. If the signal's language attribute matches any value in this list, the processor will run. If empty (default), the processor will process all signals regardless of language. **Important:** When `allowed_languages` is configured, signals without a language attribute will be skipped. | `[]` (empty, processes all) | `["javascript", "webjs", "hermesjs"]`   |

**Note:** If using Honeycomb's React Native SDK, you'll want to enable `hermesjs` as a value. See the [SDK's default attribute values](https://github.com/honeycombio/honeycomb-opentelemetry-react-native/tree/main?tab=readme-ov-file#default-attributes)

**Example configuration:**

```yaml
processors:
  source_map_symbolicator:
    allowed_languages: ["javascript", "webjs"]
```

**Behavior:**
- **Empty `allowed_languages` (default)**: Processes all signals, regardless of language attribute
- **With `allowed_languages` configured**: Only processes signals where the language attribute matches one of the allowed values (case-insensitive)
- **Missing language attribute**: Skips processing when `allowed_languages` is configured

## dSYM Symbolication
### Basic Configuration

Register the plugin in the processors section of your open telemetry collector configuration.

```yaml
    processors:
      dsym_symbolicator:
```

### dSYM files

The symbolicator requires access to the dSYM file generated by the build process.
This file must be versioned with the generated build UUID in the file name.
eg. `6A8CB813-45F6-3652-AD33-778FD1EAB196.dSYM`. The symbolicator can access this dSYM file
through a number of [different storage mechanisms documented below](#storage-mechanisms).

#### Getting the Build UUID
Given an `.xcarchive` file generated by Xcode, you can get this build uuid with the
`dwarfdump` tool. For example, the following script will find the latest build and 
upload it to the `app-archives` s3 bucket with the `ios` prefix:

<details>
<summary>example script</summary>

```shell
# Get the App Name
if [[ -z "$1" ]]; then
  echo "‚ùå Usage: $0 <TargetName>"
  exit 1
fi

TARGET_NAME=$1

export ARCHIVE_PATH=$(ls -dt ~/Library/Developer/Xcode/Archives/*/"$TARGET_NAME"*.xcarchive | head -1)
echo "üì¶ Using Archive Path: $ARCHIVE_PATH"

if [[ ! -d "$ARCHIVE_PATH" ]]; then
  echo "‚ùå Archive not found for target: $TARGET_NAME! Please archive the project first in Xcode."
  exit 1
fi

find "$ARCHIVE_PATH/dSYMs" -name "*.dSYM" | while read line ; do
   echo "üîç Found dsym at: $line"
   dsymuuid=$(dwarfdump -u "$line" | awk '{ print $2 }').dSYM
   echo "‚¨ÜÔ∏è Uploading dsym to: $dsymuuid"
   aws s3 cp --recursive "$line" s3://app-archives/ios/$dsymuuid
done
```
</details>

### Exception information format

The processor processes incoming logs and expects the stacktrace information to be formatted one of two formats: generic stack traces or metrickit reports.

#### Generic Stacktraces
Generic stacktraces must include the following attributes:

- `exception.stacktrace`
- `app.debug.build_uuid`
- `app.bundle.executable`

The processor will use `app.debug.build_uuid` to look up a corresponding dSYM, and use 
`app.bundle.executable` to find the relevant binary archive within that dSYM. It will then
attempt to symbolicate as many lines of `exception.stacktrace` as it can.

Any lines in `exception.stacktrace` that refer to unknown binaries will be left as-is.

Additionally, while they are not required or used by the processor, `exception.message`
and `exception.type` attributes are required by OTel semantic conventions, and most
downstream error sinks will expect them to be present.

#### MetricKit
MetricKit logs must include the `metrickit.diagnostic.crash.exception.stacktrace_json` attribute,
corresponding to [the `jsonRepresentation` of a MetricKit crash](https://developer.apple.com/documentation/metrickit/mxcallstacktree/jsonrepresentation()).

The processor will use `binaryUUID` and `binaryName` contained in that JSON report
to look up a corresponding dSYM and find the relevant binary archive within that dSYM. 
It will then attempt to symbolicate as many frames of the crash report as it can.

Any frames that refer to unknown binaries will be left as-is.

### Advanced Configuration

#### Attribute Mapping

The following configuration options can also be provided to change the attributes used to look for stack traces and store them.

| Config Key                                         | Description                                                                                                | Example Value                                          |
| -------------------------------------------------- | ---------------------------------------------------------------------------------------------------------- | ------------------------------------------------------ |
| `symbolicator_failure_attribute_key`               | Signals if the the symbolicator fails to fully symbolicate the stack trace                                 | `exception.symbolicator.failed`                        |
| `symbolicator_error_attribute_key`                 | Contains the error message if the the symbolicator fails to fully symbolicate the stack trace              | `exception.symbolicator.error`                         |
| `stack_trace_attribute_key`                        | Which attribute should the stack trace of a generic stacktrace log be sourced from                         | `exception.stacktrace`                                 |
| `metrickit_stack_trace_attribute_key`              | Which attribute should the json representation of a metrickit stacktrace log be sourced from               | `metrickit.diagnostic.crash.exception.stacktrace_json` |
| `output_metrickit_stack_trace_attribute_key`       | Which attribute should the symbolicated metrickit stack trace be populated into                            | `exception.stacktrace`                                 |
| `output_metrickit_exception_type_attribute_key`    | Which attribute should the exception type be populated into                                                | `exception.type`.                                      |
| `output_metrickit_exception_message_attribute_key` | Which attribute should the exception message be populated into                                             | `exception.message`.                                   |
| `preserve_stack_trace`                             | After the stack trace has been symbolicated should the original values be preserved as attributes          | `true`                                                 |
| `original_stack_trace_attribute_key`               | If the stack trace is being preserved, which key should it be copied to                                    | `exception.stacktrace.original`                        |
| `build_uuid_attribute_key`                         | Which resource attribute should the binary UUID of a generic stacktrace log be sourced from                | `app.debug.build_uuid`                                 |
| `app_executable_attribute_key`                     | Which resource attribute should the name of the app executable of a generic stacktrace log be sourced from | `app.bundle.executable`                                |


#### Additional Options

| Config Key        | Description                                                                                                 | Example Value |
| ----------------- | ----------------------------------------------------------------------------------------------------------- | ------------- |
| `timeout`         | Max duration to wait to symbolicate a stack trace in seconds.                                               | `5`           |
| `dsym_cache_size` | The maximum number of dSYMs to cache. Reduce this if you are running into memory issues with the collector. | `128`         |

#### Language-Based Routing

The dSYM processor supports language-based routing to ensure it only processes signals from iOS/macOS applications. This prevents the processor from running on signals from other platforms (like Android or JavaScript), improving performance and avoiding unnecessary processing.

| Config Key               | Description                                                                                                                                                    | Default Value             | Example Values                   |
| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------- | -------------------------------- |
| `language_attribute_key` | The attribute key that contains the programming language or SDK language of the telemetry signal.                                                              | `telemetry.sdk.language`  | `telemetry.sdk.language`         |
| `allowed_languages`      | A list of language values that this processor will handle. If the signal's language attribute matches any value in this list, the processor will run. If empty (default), the processor will process all signals regardless of language. **Important:** When `allowed_languages` is configured, signals without a language attribute will be skipped. | `[]` (empty, processes all) | `["swift", "ios"]`              |

**Example configuration:**

```yaml
processors:
  dsym_symbolicator:
    allowed_languages: ["swift", "ios"]
```

**Behavior:**
- **Empty `allowed_languages` (default)**: Processes all signals, regardless of language attribute
- **With `allowed_languages` configured**: Only processes signals where the language attribute matches one of the allowed values (case-insensitive)
- **Missing language attribute**: Skips processing when `allowed_languages` is configured

## Proguard Symbolication
### Basic Configuration

Register the plugin in the processors section of your open telemetry collector configuration.

```yaml
    processors:
      proguard_symbolicator:
```

‚ö†Ô∏è **Required Attribute:** The processor only processes logs that contain the `exception.stacktrace` attribute (or your configured `stack_trace_attribute_key`). Logs without this attribute are skipped entirely. This optimization prevents unnecessary processing of non-exception logs.

### Proguard files

The symbolicator requires access to the Proguard mapping file generated by the build process.
This file must be versioned with the generated build UUID in the file name.
eg. `6A8CB813-45F6-3652-AD33-778FD1EAB196.txt`. The symbolicator can access this proguard mapping file
through a number of [different storage mechanisms documented below](#storage-mechanisms).

### Exception information format

The processor supports two methods for receiving stack trace information:

#### 1. Structured Stack Trace Attributes (Deprecated)

The processor expects the stacktrace information to be formatted into four separate attributes:

- classes
- methods
- lines
- source_files

Each of these attributes must be a slice with each being of equal length.

Example:

```json
classes: ["com.example.Test", "com.example.Test"]
methods: ["methodA", "methodB"]
lines: [3582, 2001]
source_files: ["Test.java", "Test.java"]
```

This format is used by handled exceptions that are captured by [Honeycomb's Android SDK](https://github.com/honeycombio/honeycomb-opentelemetry-android?tab=readme-ov-file#manual-error-logging).

#### 2. Collector-Side Stack Trace Parsing

If structured stack trace attributes are not present, the processor will attempt to parse the raw stack trace string from the `exception.stacktrace` attribute (or your configured `stack_trace_attribute_key`). This collector-side parser supports standard Java/Kotlin stack trace formats and is particularly useful for **unhandled exceptions** that don't have structured attributes attached.

The parser can handle various stack trace formats including:
- Standard Java stack traces: `at com.example.Class.method(File.java:123)`
- Native methods: `at com.example.Class.method(Native Method)`
- Unknown sources: `at com.example.Class.method(Unknown Source)`
- Stack traces with missing line numbers: `at com.example.Class.method(File.java)`

When using this fallback method, the processor will:
1. Parse the exception type and message from the first line
2. Parse each stack frame to extract class, method, source file, and line number
3. Set the `exception.symbolicator.parsing_method` attribute to `"processor_parsed"`
4. Preserve any lines that couldn't be parsed as valid stack frames

**Example raw stack trace:**
```
java.lang.NullPointerException: Attempt to invoke virtual method on a null object reference
    at com.example.app.MainActivity.onCreate(MainActivity.java:42)
    at android.app.Activity.performCreate(Activity.java:8000)
    at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1309)
```

### Advanced Configuration

#### Attribute Mapping

The following configuration options can also be provided to change the attributes used to look for stack traces and store them.

| Config Key                           | Description                                                                                       | Default Value                                        |
| ------------------------------------ | ------------------------------------------------------------------------------------------------- | ---------------------------------------------------- |
| `symbolicator_failure_attribute_key` | Signals if the the symbolicator fails to fully symbolicate the stack trace                        | `exception.symbolicator.failed`                      |
| `symbolicator_error_attribute_key`   | Stores the error message that caused the symbolication to fail                                    | `exception.symbolicator.error`                       |
| `symbolicator_parsing_method_attribute_key` | Indicates which parsing method was used: `"structured_stacktrace_attributes"` (SDK-provided structured attributes) or `"processor_parsed"` (collector-side parsing of raw stack trace) | `exception.symbolicator.parsing_method`            |
| `classes_attribute_key`              | Which attribute should the classes of the stack trace be sourced from (structured route only)     | `exception.structured_stacktrace.classes`            |
| `methods_attribute_key`              | Which attribute should the methods of the stack trace be sourced from (structured route only)     | `exception.structured_stacktrace.methods`.           |
| `lines_attribute_key`                | Which attribute should the lines of the stack trace be sourced from (structured route only)       | `exception.structured_stacktrace.lines`              |
| `source_files_attribute_key`         | Which attribute should the source files of the stack trace be sourced from (structured route only) | `exception.structured_stacktrace.source_files`       |
| `stack_trace_attribute_key`          | Which attribute should the raw stack trace be sourced from (collector-parsed route) and where the symbolicated stack trace will be written to (both routes) | `exception.stacktrace`                               |
| `exception_type_attribute_key`       | Which attribute should the exception type be sourced from. If using collector-side parsing, this will be populated from the parsed stack trace | `exception.type`                                     |
| `exception_message_attribute_key`    | Which attribute should the exception message be sourced from. If using collector-side parsing, this will be populated from the parsed stack trace | `exception.message`                                  |
| `preserve_stack_trace`               | After the stack trace has been symbolicated should the original values be preserved as attributes. Applies to both structured and collector-parsed routes | `true`                                               |
| `original_stack_trace_attribute_key` | If the stack trace is being preserved which key should the original raw stack trace be copied to (both routes) | `exception.stacktrace.original`                      |
| `original_classes_attribute_key`     | If the stack trace is being preserved which key should the classes be copied to (structured route only) | `exception.structured_stacktrace.classes.original`   |
| `original_methods_attribute_key`     | If the stack trace is being preserved which key should the methods be copied to (structured route only) | `exception.structured_stacktrace.methods.original`   |
| `original_lines_attribute_key`       | If the stack trace is being preserved which key should the lines be copied to (structured route only) | `exception.structured_stacktrace.lines.original`     |
| `original_source_files_attribute_key` | If the stack trace is being preserved which key should the source files be copied to (structured route only) | `exception.structured_stacktrace.source_files.original` |
| `proguard_uuid_attribute_key`        | Which resource or log attribute should the proguard UUID be sourced from. Required for both routes | `app.debug.proguard_uuid`                            |

#### Additional Options

| Config Key            | Description                                                                                                          | Example Value |
| --------------------- | -------------------------------------------------------------------------------------------------------------------- | ------------- |
| `timeout`             | Max duration to wait to symbolicate a stack trace in seconds.                                                        | `5`           |
| `proguard_cache_size` | The maximum number of proguard files to cache. Reduce this if you are running into memory issues with the collector. | `128`         |

#### Language-Based Routing

The Proguard processor supports language-based routing to ensure it only processes signals from Android/Java/Kotlin applications. This prevents the processor from running on signals from other platforms (like iOS or JavaScript), improving performance and avoiding unnecessary processing.

| Config Key               | Description                                                                                                                                                    | Default Value             | Example Values                   |
| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------- | -------------------------------- |
| `language_attribute_key` | The attribute key that contains the programming language or SDK language of the telemetry signal.                                                              | `telemetry.sdk.language`  | `telemetry.sdk.language`         |
| `allowed_languages`      | A list of language values that this processor will handle. If the signal's language attribute matches any value in this list, the processor will run. If empty (default), the processor will process all signals regardless of language. **Important:** When `allowed_languages` is configured, signals without a language attribute will be skipped. | `[]` (empty, processes all) | `["java", "kotlin"]`             |

**Example configuration:**

```yaml
processors:
  proguard_symbolicator:
    allowed_languages: ["java", "android"]
```

**Behavior:**
- **Empty `allowed_languages` (default)**: Processes all signals, regardless of language attribute
- **With `allowed_languages` configured**: Only processes signals where the language attribute matches one of the allowed values (case-insensitive)
- **Missing language attribute**: Skips processing when `allowed_languages` is configured

## Internal Telemetry

All collector processors emit custom telemetry metrics that provides insight into its status and performance. The custom processor metrics are generated
using [mdatagen](https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/mdatagen) and include metrics such as:

- Number of stack frames processed
- Number of stack frames that failed to symbolicate
- Total source map fetch failures
- The size of the source map cache in bytes

To see the full list of the custom telemetry collected, see the the processor's `documentation.md` file.

To actually send your internal telemetry to a backend, make sure to enable the `metrics` service in your **collector's** yaml config file. Here is an example of a
collector config sending metrics to a Honeycomb endpoint:

```yaml
# ...

service:
  metrics:
    readers:
      - periodic:
          exporter:
            otlp:
              protocol: http/protobuf
              endpoint: "https://api.honeycomb.io:443" # OR, for EU instance: https://api.eu1.honeycomb.io:443
              headers:
                - name: "x-honeycomb-team"
                  value: "HONEYCOMB_API_KEY"
                - name: "x-honeycomb-dataset"
                  value: "otel-collector-metrics"

#...
```

Internal telemetry is collected by the collector by default and will be sent alongside our custom telemetry. Please visit
[Open Telemetry's Collector docs](https://opentelemetry.io/docs/collector/internal-telemetry/#lists-of-internal-metrics) for a
full list of the default internal metrics.

Additionally, all processors attach the following attributes alongside symbolicated stacktraces:

- `honeycomb.processor_type` - The processor that handled the log/trace
- `honeycomb.processor_version` - The version of the processor that handled the log/trace

## Common Storage Mechanisms

Both the Source Map and dSYM processors use the same configuration formats for loading the requires files.
The examples below are written for Source Map storage, but may easily be adapted to dSYM storage by swapping
the names of the configuration keys:

| Source Map Key      | dSYM storage equivalent | proguard storage equivalent |
| ------------------- | ----------------------- | --------------------------- |
| `source_map_store`  | `dsym_store`            | `proguard_store`            |
| `local_source_maps` | `local_dsyms`           | `local_store`               |
| `s3_source_maps`    | `s3_dsyms`              | `s3_store`                  |
| `gcs_source_maps`   | `gcs_dsyms`             | `gcs_store`                 |

### File Store

The default configuration will load the source(map) files (this must include both the JavaScript source file and the JavaScript source map file) from a local path on disk. You can set the base path that will be used.

```yaml
    processors:
      source_map_symbolicator:
        # source_map_store is used to configure which store to use, in this case local disk
        source_map_store: file_store
        local_source_maps:
          # (optional) path is used to set the base path of the files, defaults to `.`
          path: /tmp/sourcemaps
```

#### How does the file store source the files?

Each line of the stack trace includes the URL of the file it originated from.
Taking this as an example `https://example.com/static/dist/main.c383b093b0b66825a9c3.js`.
The base file name is then found `main.c383b093b0b66825a9c3.js`.
This path is joined with the configured path and then read from disk.

### S3 Store

You can also load the source(map) files (this must include both the JavaScript source file and the JavaScript source map file) from an S3 bucket.

```yaml
    processors:
      source_map_symbolicator:
        # source_map_store is used to configure which store to use, in this case S3
        source_map_store: s3_store
        # s3_source_maps is used to configure the sourcing of source maps from S3
        s3_source_maps:
          # bucket is the name of the bucket the files are stored in
          bucket: source-maps-bucket
          # (optional) region is used to configure the buckets location
          region: us-east-1
          # (optional) prefix is used to nest the files in a sub key of the bucket
          prefix: source-maps
```

#### Authentication
We use the standard [aws-sdk-go-v2](https://github.com/aws/aws-sdk-go-v2) library for interacting with S3. It automatically loads the [relevant environment variables](https://docs.aws.amazon.com/sdkref/latest/guide/environment-variables.html) for interacting with AWS S3 with a particular IAM role. To use a private S3 bucket, set the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` environment variables, and the collector will do the rest.


#### How does the S3 store source the files?

Each line of the stack trace includes the URL of the file it originated from.
Taking this as an example `https://example.com/static/dist/main.c383b093b0b66825a9c3.js`.
The base file name is then found `main.c383b093b0b66825a9c3.js`.
This path is joined with the prefix if provided and then used as the key to
source from the bucket.

### GCS Store

You can also load the source(map) files from a GCS bucket.

```yaml
    processors:
      source_map_symbolicator:
        # source_map_store is used to configure which store to use, in this case GCS
        source_map_store: gcs_store
        # gcs_source_maps is used to configure the sourcing of source maps from GCS
        gcs_source_maps:
          # bucket is the name of the bucket the files are stored in
          bucket: source-maps-bucket
          # (optional) prefix is used to nest the files in a sub key of the bucket
          prefix: source-maps
```

#### Authentication
We use the standard Google Cloud [storage](https://pkg.go.dev/cloud.google.com/go/storage) library for interacting with GCS, which uses the standard [Application Default Credentials](https://cloud.google.com/docs/authentication/application-default-credentials) for interacting with GCS. To use a private GCS bucket, set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable, and the collector will do the rest.

#### How does the GCS store source the files?

Each line of the stack trace includes the URL of the file it originated from.
Taking this as an example `https://example.com/static/dist/main.c383b093b0b66825a9c3.js`.
The base file name is then found `main.c383b093b0b66825a9c3.js`.
This path is joined with the prefix if provided and then used as the key to
source from the bucket.
